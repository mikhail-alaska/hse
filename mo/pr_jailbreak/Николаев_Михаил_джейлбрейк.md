
# Отчет по лабораторной работе "Сравнительный анализ устойчивости LLM к джейлбрейкам"

## Описание моделей 

В лабораторной работе использовались две локально запущенные языковые модели через фреймворк Ollama: mistral:7b-instruct-q4_0 и phi3:medium, условия развертывания
были одинаковые для моделей - сначала я запустил их на своем ноутбуке без графической карты результат находится в `results_laptop.csv`, 
затем на компьютере с графической картой, результат положил в файл `results_pc.csv`. Некоторые ответы являются обрезанными, так как ollama обрезает ответы по умолчанию.
Больших вычислительных мощностей у меня не было, поэтому придется отслеживать направление мыслли модели по началу ее сообщения.


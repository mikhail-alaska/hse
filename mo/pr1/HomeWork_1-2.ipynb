{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7GHPoMtZcof"
   },
   "source": [
    "# Домашнее задание: Реализация kNN, наивного байесовского классификатора, LDA, QDA\n",
    "\n",
    "Цель: Реализовать с нуля 4 классификатора, обучить их на датасете, визуализировать результаты, сравнить качество.\n",
    "\n",
    "Запрещено использовать готовые реализации из sklearn:\n",
    "   - sklearn.neighbors.KNeighborsClassifier\n",
    "   - sklearn.naive_bayes.*\n",
    "   - sklearn.discriminant_analysis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IbKp23wHZeFV"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.spatial.distance import cdist\n",
    "import pandas as pd\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Train size: {X_train.shape}, Test size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sLxbqAXrZrPP"
   },
   "outputs": [],
   "source": [
    "class MyKNNClassifier:\n",
    "    def __init__(self, k=5, weighted=False, metric='euclidean'):\n",
    "        \"\"\"\n",
    "        Инициализация классификатора kNN.\n",
    "\n",
    "        Параметры:\n",
    "        - k: количество соседей\n",
    "        - weighted: использовать взвешенное голосование или нет\n",
    "        - metric: метрика расстояния. Поддерживаемые значения:\n",
    "                  'euclidean', 'manhattan', 'chebyshev'\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.weighted = weighted\n",
    "        self.metric = metric\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        raise NotImplementedError(\"Реализуйте метод fit для kNN\")\n",
    "\n",
    "    def _compute_distances(self, X):\n",
    "        \"\"\"\n",
    "        Вычисляет расстояния от каждой точки в X до всех точек в X_train.\n",
    "\n",
    "        Возвращает матрицу расстояний формы (n_samples, n_train_samples)\n",
    "        \"\"\"\n",
    "        if self.metric == 'euclidean':\n",
    "            pass\n",
    "        elif self.metric == 'manhattan':\n",
    "            pass\n",
    "        elif self.metric == 'chebyshev':\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Метрика '{self.metric}' не поддерживается. Используйте: 'euclidean', 'manhattan', 'chebyshev'.\")\n",
    "\n",
    "        return distances\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 1. Посчитайте расстояния от каждой точки в X до всех точек в X_train (_compute_distances)\n",
    "        # 2. Для каждой точки найдите индексы k ближайших соседей\n",
    "        # 3. Получите метки этих соседей\n",
    "        # 4. Если weighted=False — голосование по большинству\n",
    "        #    Если weighted=True — взвешенное голосование (вес = 1 / (расстояние + 1e-5))\n",
    "        # 5. Верните предсказанные метки\n",
    "        raise NotImplementedError(\"Реализуйте метод predict для kNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyfCIKISdI1n"
   },
   "source": [
    "## Наивный байесовский классификатор (Gaussian Naive Bayes)\n",
    "\n",
    "Наивный байесовский классификатор основан на **теореме Байеса** и предположении о **условной независимости признаков** относительно класса.\n",
    "\n",
    "---\n",
    "\n",
    "### Теорема Байеса:\n",
    "\n",
    "Вероятность принадлежности объекта к классу $ c $ при наблюдении признакового вектора $ \\mathbf{x} = (x_1, x_2, \\dots, x_d) $:\n",
    "\n",
    "$$\n",
    "P(y = c \\mid \\mathbf{x}) = \\frac{P(\\mathbf{x} \\mid y = c) \\cdot P(y = c)}{P(\\mathbf{x})}\n",
    "$$\n",
    "\n",
    "Так как $ P(\\mathbf{x}) $ одинакова для всех классов, для классификации достаточно максимизировать **числитель** — **апостериорную вероятность**:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\underset{c}{\\mathrm{argmax}} \\; P(y = c) \\cdot P(\\mathbf{x} \\mid y = c)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Предположение \"наивности\":\n",
    "\n",
    "Признаки условно независимы при заданном классе:\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x} \\mid y = c) = \\prod_{j=1}^{d} P(x_j \\mid y = c)\n",
    "$$\n",
    "\n",
    "Тогда:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\underset{c}{\\mathrm{argmax}} \\; P(y = c) \\cdot \\prod_{j=1}^{d} P(x_j \\mid y = c)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Для непрерывных признаков: предположение о нормальном распределении\n",
    "\n",
    "Часто предполагают, что каждый признак $ x_j $ в классе $ c $ распределён нормально:\n",
    "\n",
    "$$\n",
    "x_j \\mid y = c \\; \\sim \\; \\mathcal{N}(\\mu_{jc}, \\sigma_{jc}^2)\n",
    "$$\n",
    "\n",
    "Тогда:\n",
    "\n",
    "$$\n",
    "P(x_j \\mid y = c) = \\frac{1}{\\sqrt{2\\pi \\sigma_{jc}^2}} \\exp\\left( -\\frac{(x_j - \\mu_{jc})^2}{2\\sigma_{jc}^2} \\right)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Что нужно оценить на обучающей выборке:\n",
    "\n",
    "- Априорные вероятности:  \n",
    "  $ \\pi_c = \\frac{\\text{количество объектов класса } c}{\\text{общее количество объектов}} $\n",
    "\n",
    "- Средние:  \n",
    "  $ \\mu_{jc} = \\frac{1}{n_c} \\sum_{i: y_i = c} x_{ij} $\n",
    "\n",
    "- Дисперсии:  \n",
    "  $ \\sigma_{jc}^2 = \\frac{1}{n_c} \\sum_{i: y_i = c} (x_{ij} - \\mu_{jc})^2 $\n",
    "\n",
    "(где $ n_c $ — количество объектов класса $ c $)\n",
    "\n",
    "---\n",
    "\n",
    "**Ваша задача**: реализовать этот классификатор с нуля в классе `MyGaussianNB`, используя описанные формулы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VzDjyqf-ZyZ4"
   },
   "outputs": [],
   "source": [
    "class MyGaussianNB:\n",
    "    def __init__(self):\n",
    "        self.classes = None\n",
    "        self.mean = None       # среднее по каждому признаку для каждого класса\n",
    "        self.var = None        # дисперсия по каждому признаку для каждого класса\n",
    "        self.priors = None     # априорные вероятности классов\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # 1. Найдите уникальные классы\n",
    "        # 2. Для каждого класса:\n",
    "        #    - оцените mean и var для каждого признака\n",
    "        #    - оцените prior = количество примеров класса / всего примеров\n",
    "        # 3. Сохраните всё в атрибуты класса\n",
    "        raise NotImplementedError(\"Реализуйте метод fit для Naive Bayes\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 1. Для каждой точки X и каждого класса вычислите логарифм правдоподобия + логарифм prior\n",
    "        #    (используйте формулу нормального распределения в логарифмическом виде)\n",
    "        # 2. Выберите класс с максимальным значением\n",
    "        # 3. Верните предсказания\n",
    "        raise NotImplementedError(\"Реализуйте метод predict для Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBXHHPTJeCk_"
   },
   "source": [
    "## Линейный (LDA) и квадратичный (QDA) дискриминантный анализ Фишера\n",
    "\n",
    "LDA и QDA — это **параметрические методы классификации**, основанные на предположении, что признаки в каждом классе распределены **нормально**.\n",
    "\n",
    "---\n",
    "\n",
    "### Общая постановка\n",
    "\n",
    "Пусть дано:\n",
    "- $ \\mathbf{x} \\in \\mathbb{R}^d $ — вектор признаков,\n",
    "- $ y \\in \\{1, 2, \\dots, K\\} $ — метка класса,\n",
    "- $ \\pi_k = P(y = k) $ — априорная вероятность класса $ k $,\n",
    "- $ f_k(\\mathbf{x}) = P(\\mathbf{x} \\mid y = k) $ — функция правдоподобия.\n",
    "\n",
    "Предполагаем, что:\n",
    "$$\n",
    "\\mathbf{x} \\mid y = k \\; \\sim \\; \\mathcal{N}(\\boldsymbol{\\mu}_k, \\mathbf{\\Sigma}_k)\n",
    "$$\n",
    "\n",
    "Тогда:\n",
    "$$\n",
    "f_k(\\mathbf{x}) = \\frac{1}{(2\\pi)^{d/2} |\\mathbf{\\Sigma}_k|^{1/2}} \\exp\\left( -\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu}_k)^\\top \\mathbf{\\Sigma}_k^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}_k) \\right)\n",
    "$$\n",
    "\n",
    "По теореме Байеса:\n",
    "$$\n",
    "P(y = k \\mid \\mathbf{x}) = \\frac{\\pi_k f_k(\\mathbf{x})}{\\sum_{l=1}^K \\pi_l f_l(\\mathbf{x})}\n",
    "$$\n",
    "\n",
    "Классификатор выбирает класс с **максимальной апостериорной вероятностью**:\n",
    "$$\n",
    "\\hat{y} = \\underset{k}{\\mathrm{argmax}} \\; \\pi_k f_k(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Переход к дискриминантным функциям\n",
    "\n",
    "Вместо сравнения вероятностей удобнее сравнивать **логарифмы** (монотонное преобразование):\n",
    "\n",
    "$$\n",
    "\\delta_k(\\mathbf{x}) = \\log \\left( \\pi_k f_k(\\mathbf{x}) \\right) = \\log \\pi_k + \\log f_k(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "Подставим выражение для $ f_k(\\mathbf{x}) $:\n",
    "\n",
    "$$\n",
    "\\delta_k(\\mathbf{x}) = \\log \\pi_k - \\frac{1}{2} \\log |\\mathbf{\\Sigma}_k| - \\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu}_k)^\\top \\mathbf{\\Sigma}_k^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}_k) + \\text{const}\n",
    "$$\n",
    "\n",
    "(где `const` не зависит от $ k $, поэтому его можно игнорировать при сравнении)\n",
    "\n",
    "---\n",
    "\n",
    "## Линейный дискриминантный анализ (LDA)\n",
    "\n",
    "**Предположение**: ковариационные матрицы **одинаковы** для всех классов:\n",
    "\n",
    "$$\n",
    "\\mathbf{\\Sigma}_k = \\mathbf{\\Sigma} \\quad \\forall k\n",
    "$$\n",
    "\n",
    "Тогда:\n",
    "- $ \\log |\\mathbf{\\Sigma}_k| $ — константа → исключается,\n",
    "- $ \\mathbf{\\Sigma}_k^{-1} = \\mathbf{\\Sigma}^{-1} $ — общая для всех классов.\n",
    "\n",
    "Раскрываем квадратичную форму:\n",
    "\n",
    "$$\n",
    "(\\mathbf{x} - \\boldsymbol{\\mu}_k)^\\top \\mathbf{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}_k) = \\mathbf{x}^\\top \\mathbf{\\Sigma}^{-1} \\mathbf{x} - 2 \\boldsymbol{\\mu}_k^\\top \\mathbf{\\Sigma}^{-1} \\mathbf{x} + \\boldsymbol{\\mu}_k^\\top \\mathbf{\\Sigma}^{-1} \\boldsymbol{\\mu}_k\n",
    "$$\n",
    "\n",
    "Первое слагаемое не зависит от $ k $ → исключается.\n",
    "\n",
    "Остаётся **линейная** дискриминантная функция:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\delta_k^{\\text{LDA}}(\\mathbf{x}) = \\boldsymbol{\\mu}_k^\\top \\mathbf{\\Sigma}^{-1} \\mathbf{x} - \\frac{1}{2} \\boldsymbol{\\mu}_k^\\top \\mathbf{\\Sigma}^{-1} \\boldsymbol{\\mu}_k + \\log \\pi_k\n",
    "}\n",
    "$$\n",
    "\n",
    "Решающие границы — **линейные** (гиперплоскости).\n",
    "\n",
    "---\n",
    "\n",
    "## Квадратичный дискриминантный анализ (QDA)\n",
    "\n",
    "**Предположение**: ковариационные матрицы **разные** для каждого класса: $ \\mathbf{\\Sigma}_k $.\n",
    "\n",
    "Тогда дискриминантная функция остаётся **квадратичной**:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\delta_k^{\\text{QDA}}(\\mathbf{x}) = -\\frac{1}{2} \\log |\\mathbf{\\Sigma}_k| - \\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu}_k)^\\top \\mathbf{\\Sigma}_k^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}_k) + \\log \\pi_k\n",
    "}\n",
    "$$\n",
    "\n",
    "Решающие границы — **квадратичные поверхности** (параболы, эллипсы и т.д. в 2D).\n",
    "\n",
    "---\n",
    "\n",
    "## Что нужно оценить на обучающей выборке\n",
    "\n",
    "Для обоих методов:\n",
    "\n",
    "- **Априорные вероятности**:  \n",
    "  $ \\pi_k = \\frac{n_k}{n} $, где $ n_k $ — число объектов класса $ k $\n",
    "\n",
    "- **Средние векторы**:  \n",
    "  $ \\boldsymbol{\\mu}_k = \\frac{1}{n_k} \\sum_{i: y_i = k} \\mathbf{x}_i $\n",
    "\n",
    "Для **LDA**:\n",
    "- **Общая ковариационная матрица**:\n",
    "  $$\n",
    "  \\mathbf{\\Sigma} = \\frac{1}{n - K} \\sum_{k=1}^K \\sum_{i: y_i = k} (\\mathbf{x}_i - \\boldsymbol{\\mu}_k)(\\mathbf{x}_i - \\boldsymbol{\\mu}_k)^\\top\n",
    "  $$\n",
    "\n",
    "Для **QDA**:\n",
    "- **Ковариационная матрица для каждого класса**:\n",
    "  $$\n",
    "  \\mathbf{\\Sigma}_k = \\frac{1}{n_k - 1} \\sum_{i: y_i = k} (\\mathbf{x}_i - \\boldsymbol{\\mu}_k)(\\mathbf{x}_i - \\boldsymbol{\\mu}_k)^\\top\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Ваша задача**: реализовать оба метода в классе `MyLDAQDA` с параметром `mode='LDA'` или `'QDA'`, используя приведённые формулы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AM-OZhqqcjbv"
   },
   "outputs": [],
   "source": [
    "class MyLDAQDA:\n",
    "    def __init__(self, mode='LDA'):  # mode может быть 'LDA' или 'QDA'\n",
    "        self.mode = mode\n",
    "        self.classes = None\n",
    "        self.mean = None\n",
    "        self.cov = None        # для LDA — одна общая матрица, для QDA — список матриц\n",
    "        self.priors = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # 1. Найдите уникальные классы\n",
    "        # 2. Для каждого класса:\n",
    "        #    - оцените mean\n",
    "        #    - оцените prior\n",
    "        # 3. Для LDA: посчитайте общую ковариационную матрицу (взвешенную по классам)\n",
    "        #    Для QDA: посчитайте отдельную ковариационную матрицу для каждого класса\n",
    "        # 4. Регуляризация: добавьте np.eye(d) * 1e-6 к ковариационной матрице, чтобы избежать вырожденности\n",
    "        raise NotImplementedError(\"Реализуйте метод fit для LDA/QDA\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 1. Для каждой точки и каждого класса вычислите дискриминантную функцию δ_k(x):\n",
    "        # 2. Выберите класс с максимальным δ_k(x)\n",
    "        # 3. Верните предсказания\n",
    "        raise NotImplementedError(\"Реализуйте метод predict для LDA/QDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Tinhn26hbV-"
   },
   "source": [
    "## Для метода kNN:\n",
    "Проведите кросс-валидацию (например, 5-fold) на обучающей выборке для значений k = 1, 2, ..., 30.\n",
    "\n",
    "\n",
    "Для каждого k посчитайте среднюю Accuracy (долю верных ответов - среднюю по всем классам) по фолдам.\n",
    "\n",
    "\n",
    "Постройте график: k → accuracy (два графика: обычный и взвешенный kNN).\n",
    "\n",
    "Выберите k, при котором accuracy максимальна — используйте его для финального тестирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ggQDOx_diOW9"
   },
   "outputs": [],
   "source": [
    "# Ваш код ниже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVApo6TxhxDO"
   },
   "source": [
    "## Для наивного байесовского классификатора и линейного и квадратичного дискриминантного анализа\n",
    "\n",
    "Обучите модели на обучающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Fqrj-JFKfrpq"
   },
   "outputs": [],
   "source": [
    "# Ваш код ниже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBVu_sLJji1W"
   },
   "source": [
    "## Для всех моделей\n",
    "\n",
    "Вызовите методы для предсказания на данных из тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "kk--hddmj5nY"
   },
   "outputs": [],
   "source": [
    "# Ваш код ниже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHyPFW7OiXhR"
   },
   "source": [
    "## Метрики качества классификации\n",
    "\n",
    "Для оценки качества классификаторов используются следующие метрики. Обозначения:\n",
    "\n",
    "- $ TP $ — True Positive (верно предсказанные положительные примеры)\n",
    "- $ TN $ — True Negative\n",
    "- $ FP $ — False Positive (ложные срабатывания)\n",
    "- $ FN $ — False Negative (пропущенные положительные)\n",
    "\n",
    "Для многоклассовой классификации используется **макро-усреднение** — метрика считается отдельно для каждого класса, затем берётся среднее.\n",
    "\n",
    "---\n",
    "\n",
    "### Accuracy (доля правильных ответов)\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Precision (точность — доля верных срабатываний среди всех предсказанных положительных)\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Recall (полнота — доля найденных положительных среди всех реальных положительных)\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### F1-мера (гармоническое среднее precision и recall)\n",
    "\n",
    "$$\n",
    "F1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "F1-мера полезна, когда классы несбалансированы — она \"наказывает\" за сильный дисбаланс между precision и recall.\n",
    "\n",
    "### Задача:\n",
    "Для каждой модели подсчитать вышеописанные метрики для каждого из классов и вывести в виде таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "FFOe9lpWiWHZ"
   },
   "outputs": [],
   "source": [
    "# Ваш код ниже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ii-3YvISk3rr"
   },
   "source": [
    "## Вопросы для подготовки к защите\n",
    "\n",
    "Что такое kNN? Почему он называется \"ленивым\" алгоритмом?\n",
    "\n",
    "Как работает взвешенный kNN? Какие функции весов вы знаете?\n",
    "\n",
    "Почему в kNN важно нормировать признаки?\n",
    "\n",
    "Как вы подбирали оптимальное k? Почему не стоит брать k=1 или k=N?\n",
    "\n",
    "В чём смысл кросс-валидации? Почему нельзя просто выбрать k по максимальной точности на обучающей выборке?\n",
    "\n",
    "Какие метрики расстояния вы реализовали? Чем отличается Манхэттенское расстояние от Евклидова? Когда какое лучше?\n",
    "\n",
    "Объясните формулу наивного байесовского классификатора. Почему он \"наивный\"?\n",
    "\n",
    "Какие предположения делает Gaussian Naive Bayes?\n",
    "\n",
    "Чем отличается LDA от QDA? В каких случаях какой метод предпочтительнее?\n",
    "\n",
    "Почему в LDA решающие границы — линейные, а в QDA — квадратичные? Покажите на формулах.\n",
    "\n",
    "Запишите формулы для accuracy, precision, recall и F1-score через TP, TN, FP, FN.\n",
    "\n",
    "Почему accuracy не всегда адекватная метрика? Приведите пример, когда accuracy высокая, но модель бесполезна.\n",
    "\n",
    "Что такое макро-усреднение (macro-average)? Почему мы его используем в многоклассовой классификации?\n",
    "\n",
    "В чём разница между macro-F1 и micro-F1? Когда какой предпочтительнее?\n",
    "\n",
    "Почему F1-мера — это гармоническое среднее, а не арифметическое? Как это влияет на интерпретацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNjfmeOVk5mM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

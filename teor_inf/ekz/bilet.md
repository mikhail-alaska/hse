## 1.Понятие энтропии случайной величины. Основные свойства энтропии (верхняя и нижняя оценки на величину энтропии дискретной СВ)

Понятие энтропии - пусть U - дискретная случайная величина: которая принимает значения
из множества *u*. Тогда энтропия - это ожидаемый сюрприз случайной величины:
$$
H(U)=E(s(u))=\Sigma_{u\in U} p(u) log_2 \frac {1}{p(u)}
$$
